{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional neural network for MNIST classification\n",
    "The task is to classify MNIST dataset, series of grey-scale images with resolution 28x28 pixels (784 features). While this resolution is manageable in classic feedforward neural network architecture with 784 input neurons, most images have way more pixels and 3 color channels. For example 4K Ultra HD resolution is 3840 x 2160 x 3 channels, which would be 24 883 200 different neurons. Regular networks are therefore not scaleable for image classificaton.  \n",
    "Fortunately, there is little correlation between 2 pixels in picture unless the pixels are very close to each other. The fully connected architecture is therefore not necessary and it leads us to the idea of convolutional and pooling layers.\n",
    "#### Convolutional layer\n",
    "This layer is the first one that extracts features from images via convolution - it preserves the relationships between different parts of an image, while filtering the image with a smaller pixel filter to decrease the resolution. When we apply a 4x4 filter on a 7x7 image, we will get 4x4 output, which is 67% decrease in number of pixels.\n",
    "#### Pooling layer\n",
    "Pooling layer is usually inserted after a convolutional layer to reduce the spatial size of the representation, which reduces the parameter counts and overall computational complexity. A pooling size is selected (e.g. 2x2) and then a maximum / average / sum is calculated for window of pixels.\n",
    "#### Fully connected layers\n",
    "This is the architecture of classic neural network, where each parameter is linked to one another. The output of last pooling layer is the input for fully connected layers.  \n",
    "<figure>\n",
    "    <img src=\"images/convolutional_architecture.jpeg\" width=\"80%\"/>\n",
    "    <figcaption>Convolutional network architecture. MathWorks, Introducing Deep Learning with MATLAB, https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/d/80879v00_Deep_Learning_ebook.pdf</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package imports, data loading, image plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train type: <class 'numpy.ndarray'>\n",
      "y_train type: <class 'numpy.ndarray'>\n",
      "x_train original shape: (60000, 28, 28)\n",
      "y_train original shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"x_train type: {}\".format(type(x_train)))\n",
    "print(\"y_train type: {}\".format(type(y_train)))\n",
    "print(\"x_train original shape: {}\".format(x_train.shape))\n",
    "print(\"y_train original shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve kernel problems during training of CNN\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot several images from the train set\n",
    "plt.figure(figsize=(16,5))\n",
    "picture_indeces = [444,666,7788,13987,33145]\n",
    "for i in range(len(picture_indeces)):\n",
    "    ax = plt.subplot(1,len(picture_indeces),i+1)\n",
    "    image_index = picture_indeces[i]\n",
    "    plt.imshow(x_train[image_index], cmap='Greys')\n",
    "    #don't show ticks and labels\n",
    "    plt.tick_params(axis='x',which='both', bottom=False, labelbottom=False)\n",
    "    plt.tick_params(axis='y',which='both', left=False, labelleft=False)\n",
    "    plt.title(\"Image label: \\\"{}\\\"\".format(y_train[image_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prepropcessing - reshaping, normalization\n",
    "Keras API accepts 4-dims numpy arrays, MNIST has 3-dims. Data for all neural network models needs to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"x_test shape: {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional network implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always possible to experiment with kernel size, pool size, activation functions, dropout rate, and number of neurons in the first Dense layer to get a better result. The shape of input layer and number of neurons in output layer is determined by our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/mnist_nn/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/mnist_nn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape)) #convolutional layer\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))                         #pooling layer\n",
    "cnn.add(Flatten())                                              #flattening for fully connected layer\n",
    "cnn.add(Dense(128, activation=tf.nn.relu))                      #fully connected layer with ReLU activation function (128 neurons, but this number can be tuned)\n",
    "cnn.add(Dropout(0.2))                                           #disregard selected neurons to fight overfitting\n",
    "cnn.add(Dense(10,activation=tf.nn.softmax))                     #softmax output layer (10 classes in MNIST means that there need to be 10 neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, loss function, metrics and epochs can also be tuned. Other optimizers are usually outperformed by _adam_ optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/mnist_nn/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.2047 - acc: 0.9376\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0841 - acc: 0.9745\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0600 - acc: 0.9817\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0467 - acc: 0.9852\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0362 - acc: 0.9874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0312 - acc: 0.9895\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0273 - acc: 0.9909\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0235 - acc: 0.9918\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0205 - acc: 0.9929\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0198 - acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b892080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam', \n",
    "            loss='sparse_categorical_crossentropy', \n",
    "            metrics=['accuracy'])\n",
    "cnn.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 970us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06352144173665401, 0.9843]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after only 10 epochs, the model has accuracy of 98.43%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model saving\n",
    "It is not recommended to use pickle or cPickle to save a Keras model. Use `model.save(filepath)` to save a Keras model into a single HDF5 file which will contain:\n",
    "- the architecture of the model, allowing to re-create the model\n",
    "- the weights of the model\n",
    "- the training configuration (loss, optimizer)\n",
    "- the state of the optimizer, allowing to resume training exactly where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# loaded_model = load_model('cnn_model.h5')\n",
    "# loaded_model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
